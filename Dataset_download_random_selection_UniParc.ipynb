{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a63b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download proteins and other features from InterPro for a given pfam protein family\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import random\n",
    "import requests\n",
    "from urllib.error import HTTPError\n",
    "from urllib.request import urlopen\n",
    "from time import sleep\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c6054-6651-43d8-8fcd-b820bebfa685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 / 248842690\n",
      "1000 / 248842690\n",
      "1500 / 248842690\n",
      "2000 / 248842690\n",
      "2500 / 248842690\n",
      "3000 / 248842690\n",
      "3500 / 248842690\n",
      "4000 / 248842690\n",
      "4500 / 248842690\n",
      "5000 / 248842690\n",
      "5500 / 248842690\n",
      "6000 / 248842690\n",
      "6500 / 248842690\n"
     ]
    }
   ],
   "source": [
    "re_next_link = re.compile(r'<(.+)>; rel=\"next\"')\n",
    "retries = Retry(total=5, backoff_factor=0.25, status_forcelist=[500, 502, 503, 504])\n",
    "session = requests.Session()\n",
    "session.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "results = []\n",
    "\n",
    "def get_next_link(headers):\n",
    "    if \"Link\" in headers:\n",
    "        match = re_next_link.match(headers[\"Link\"])\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "\n",
    "def get_batch(batch_url):\n",
    "    while batch_url:\n",
    "        response = session.get(batch_url)\n",
    "        response.raise_for_status()\n",
    "        total = response.headers[\"x-total-results\"]\n",
    "        yield response, total\n",
    "        batch_url = get_next_link(response.headers)\n",
    "\n",
    "url = 'https://rest.uniprot.org/uniprotkb/search?format=json&query=%28*%29&size=500'\n",
    "interactions = {}\n",
    "for batch, total in get_batch(url):\n",
    "    json_object = json.loads(batch.text)\n",
    "    tmp_results = json_object['results']\n",
    "    # print(json_object['results'][0].keys())\n",
    "    for i in tmp_results:\n",
    "        results.append(i)\n",
    "    print(f'{len(results)} / {total}')\n",
    "    if len(results) >= 100000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b87b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fede856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Create a directory named \"data\" in the current working directory if it doesn't exist\n",
    "data_dir = \"data_random_selection_uniParc\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Save filtered_data as a .p file\n",
    "filtered_data_file = os.path.join(data_dir, \"not_filtered_data_uniParc.p\")\n",
    "with open(filtered_data_file, \"wb\") as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16fe39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN UNFILTERED DATA------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb21b5-d1e2-4a9b-8608-2112aa4faf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f2f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the downloaded data TODO------------------------------------\n",
    "total_len = 0\n",
    "total_sequences = 0\n",
    "filtered_data = []\n",
    "\n",
    "count = 1\n",
    "for sequence in results:\n",
    "    if sequence:\n",
    "        keys = sequence.keys()\n",
    "        if 'sequence' in keys:\n",
    "            seq = sequence['sequence']\n",
    "            # print(seq)\n",
    "            length = seq[\"length\"]\n",
    "            total_len += length\n",
    "            total_sequences += 1\n",
    "            filtered_data.append(sequence)\n",
    "            # for debugging:\n",
    "            # break\n",
    "    \n",
    "    \n",
    "print(\"Sequences retrieved: \", total_sequences)\n",
    "print(\"Sequence average length: \", total_len/total_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c444f954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences retrieved:  100000\n",
      "Sequence average length:  556.26958\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Calculate the number of entries to select (10% of the data)\n",
    "# ID_test_percentage = 0.1\n",
    "# num_entries_to_select = int(len(filtered_data) * ID_test_percentage)\n",
    "\n",
    "# Randomly select ID_test_percentage of the data entries\n",
    "# random_selection = random.sample(filtered_data, num_entries_to_select)\n",
    "\n",
    "# Print the randomly selected entries\n",
    "#for entry in random_selection:\n",
    "#    print(entry)\n",
    "#    break\n",
    "\n",
    "# Remove the randomly selected entries from `filtered_data` if needed\n",
    "# filtered_data = [entry for entry in filtered_data if entry not in random_selection]\n",
    "print(\"Sequences retrieved: \", total_sequences)\n",
    "print(\"Sequence average length: \", total_len/total_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filtered_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fef950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Create a directory named \"data\" in the current working directory if it doesn't exist\n",
    "data_dir = \"data_random_selection_uniParc\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Save filtered_data as a .p file\n",
    "filtered_data_file = os.path.join(data_dir, \"filtered_data.p\")\n",
    "with open(filtered_data_file, \"wb\") as file:\n",
    "    pickle.dump(filtered_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save random_selection of 10 proteins as a .p file\n",
    "random_selection = random.sample(filtered_data, 10)\n",
    "random_selection_file = os.path.join(data_dir, \"random_selection_10.p\")\n",
    "with open(random_selection_file, \"wb\") as file:\n",
    "    pickle.dump(random_selection, file)\n",
    "# Save random_selection of 100 proteins as a .p file\n",
    "random_selection = random.sample(filtered_data, 100)\n",
    "random_selection_file = os.path.join(data_dir, \"random_selection_100.p\")\n",
    "with open(random_selection_file, \"wb\") as file:\n",
    "    pickle.dump(random_selection, file)\n",
    "# Save random_selection of 500 proteins as a .p file\n",
    "random_selection = random.sample(filtered_data, 500)\n",
    "random_selection_file = os.path.join(data_dir, \"random_selection_500.p\")\n",
    "with open(random_selection_file, \"wb\") as file:\n",
    "    pickle.dump(random_selection, file)\n",
    "# Save random_selection of 1000 proteins as a .p file\n",
    "random_selection = random.sample(filtered_data, 1000)\n",
    "random_selection_file = os.path.join(data_dir, \"random_selection_1000.p\")\n",
    "with open(random_selection_file, \"wb\") as file:\n",
    "    pickle.dump(random_selection, file)\n",
    "# Save random_selection of 2000 proteins as a .p file\n",
    "random_selection = random.sample(filtered_data, 2000)\n",
    "random_selection_file = os.path.join(data_dir, \"random_selection_2000.p\")\n",
    "with open(random_selection_file, \"wb\") as file:\n",
    "    pickle.dump(random_selection, file)\n",
    "# Save random_selection of 5000 proteins as a .p file\n",
    "random_selection = random.sample(filtered_data, 5000)\n",
    "random_selection_file = os.path.join(data_dir, \"random_selection_5000.p\")\n",
    "with open(random_selection_file, \"wb\") as file:\n",
    "    pickle.dump(random_selection, file)\n",
    "# Save random_selection of 10000 proteins as a .p file\n",
    "random_selection = random.sample(filtered_data, 10000)\n",
    "random_selection_file = os.path.join(data_dir, \"random_selection_10000.p\")\n",
    "with open(random_selection_file, \"wb\") as file:\n",
    "    pickle.dump(random_selection, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809bdba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
