{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tied_embedding_softmax.w\n",
      "torch.Size([129407, 1280])\n",
      "-----------------------------------\n",
      "tied_embedding_softmax.b\n",
      "torch.Size([129407])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer0.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer0.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer1.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer1.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer2.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer2.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer3.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer3.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer4.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer4.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer5.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer5.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer6.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer6.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer7.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer7.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer8.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer8.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer9.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer9.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer10.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer10.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer11.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer11.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer12.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer12.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer13.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer13.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer14.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer14.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer15.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer15.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer16.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer16.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer17.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer17.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer18.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer18.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer19.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer19.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer20.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer20.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer21.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer21.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer22.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer22.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer23.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer23.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer24.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer24.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer25.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer25.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer26.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer26.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer27.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer27.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer28.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer28.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer29.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer29.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer30.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer30.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer31.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer31.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer32.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer32.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer33.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer33.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer34.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer34.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer35.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer35.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layernorm.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layernorm.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_path = 'ckpt/pretrain_progen_full.pth'\n",
    "model_ordered_dict = torch.load(model_path)\n",
    "#each key is a layer name, and each value is a tensor\n",
    "for key in model_ordered_dict:\n",
    "    print(key)\n",
    "    print(model_ordered_dict[key].shape)\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10061\n"
     ]
    }
   ],
   "source": [
    "class VocabularyManager:\n",
    "    def __init__(self,  vocab_loc = 'mapping_files/vocab.txt'):\n",
    "        with open(vocab_loc, encoding='utf-8') as file:\n",
    "            self.vocab = file.read().split('\\n')[:-1]\n",
    "        self.vocab = list(map(lambda x: x.split(' ')[0], self.vocab))\n",
    "        self.vocab_size = len(self.vocab) \n",
    "\n",
    "Vocab = VocabularyManager()\n",
    "print(Vocab.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.nn.Parameter(torch.normal(0., 1e-2, size=(Vocab.vocab_size, 1280)))\n",
    "bias = torch.nn.Parameter(torch.zeros(Vocab.vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substitute the weights and bias in the model with the new weights and bias\n",
    "model_ordered_dict['tied_embedding_softmax.w'] = weights\n",
    "model_ordered_dict['tied_embedding_softmax.b'] = bias\n",
    "\n",
    "#save the new model\n",
    "#torch.save(model_ordered_dict, 'ckpt/pretrain_progen_full_vocab_scop.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tied_embedding_softmax.w\n",
      "torch.Size([10061, 1280])\n",
      "-----------------------------------\n",
      "tied_embedding_softmax.b\n",
      "torch.Size([10061])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer0.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer0.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer0.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer1.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer1.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer1.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer2.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer2.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer2.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer3.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer3.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer3.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer4.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer4.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer4.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer5.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer5.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer5.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer6.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer6.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer6.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer7.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer7.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer7.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer8.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer8.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer8.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer9.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer9.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer9.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer10.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer10.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer10.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer11.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer11.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer11.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer12.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer12.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer12.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer13.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer13.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer13.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer14.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer14.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer14.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer15.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer15.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer15.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer16.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer16.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer16.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer17.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer17.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer17.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer18.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer18.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer18.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer19.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer19.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer19.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer20.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer20.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer20.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer21.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer21.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer21.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer22.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer22.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer22.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer23.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer23.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer23.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer24.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer24.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer24.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer25.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer25.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer25.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer26.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer26.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer26.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer27.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer27.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer27.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer28.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer28.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer28.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer29.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer29.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer29.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer30.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer30.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer30.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer31.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer31.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer31.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer32.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer32.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer32.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer33.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer33.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer33.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer34.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer34.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer34.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wq.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wq.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wk.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wk.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wv.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.Wv.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.dense.weight\n",
      "torch.Size([1280, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.multi_head_attention.dense.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.ffn.0.weight\n",
      "torch.Size([8192, 1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.ffn.0.bias\n",
      "torch.Size([8192])\n",
      "-----------------------------------\n",
      "encoder.layer35.ffn.2.weight\n",
      "torch.Size([1280, 8192])\n",
      "-----------------------------------\n",
      "encoder.layer35.ffn.2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.layernorm1.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.layernorm1.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.layernorm2.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layer35.layernorm2.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layernorm.weight\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n",
      "encoder.layernorm.bias\n",
      "torch.Size([1280])\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in model_ordered_dict:\n",
    "    print(key)\n",
    "    print(model_ordered_dict[key].shape)\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ordered_dict, 'ckpt/pretrain_progen_full_vocab_scop.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
