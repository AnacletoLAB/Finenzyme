{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 10035, 'C': 10036, 'D': 10037, 'E': 10038, 'F': 10039, 'G': 10040, 'H': 10041, 'I': 10042, 'J': 10043, 'K': 10044, 'L': 10045, 'M': 10046, 'N': 10047, 'O': 10048, 'P': 10049, 'Q': 10050, 'R': 10051, 'S': 10052, 'T': 10053, 'U': 10054, 'V': 10055, 'W': 10056, 'X': 10057, 'Y': 10058, 'Z': 10059}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pickle = pd.read_pickle(\"mapping_files/aa_to_ctrl_idx.p\")\n",
    "print(pickle)\n",
    "#remove key 'PAD' from dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_csv('vocab.txt', sep=' ', header=None, names=['tag', 'token'])\n",
    "AA_MAP = df[-26:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dict for all letters and pad based on AA_MAP\n",
    "aa_dict = {}\n",
    "for i in range(AA_MAP.shape[0]):\n",
    "    aa_dict[AA_MAP.iloc[i, 0]] = AA_MAP.iloc[i, 1]\n",
    "\n",
    "#to pickle\n",
    "import pickle\n",
    "with open('mapping_files/aa_to_ctrl_idx.p1', 'wb') as f:\n",
    "    pickle.dump(aa_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0774, -0.0222, -0.0793,  ...,  0.0542, -0.0569, -0.0739],\n",
       "        [-0.1208, -0.0681,  0.0108,  ...,  0.0699,  0.0405,  0.0049],\n",
       "        [ 0.0052,  0.0363,  0.1306,  ...,  0.1271,  0.1416, -0.1366],\n",
       "        ...,\n",
       "        [ 0.0126, -0.0490, -0.0362,  ...,  0.0339,  0.1410, -0.0558],\n",
       "        [-0.0801, -0.0731,  0.0359,  ...,  0.0206, -0.0910,  0.0277],\n",
       "        [-0.1167,  0.0427, -0.0466,  ...,  0.0325,  0.0301,  0.0130]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "cp = torch.load('ckpt/pretrain_progen_full.pth', map_location=torch.device('cpu'))\n",
    "\n",
    "#get model shape\n",
    "cp.pop('tied_embedding_softmax.w', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10061, 1280]), torch.Size([10061]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_manager import VocabularyManager, TiedEmbeddingSoftmax\n",
    "\n",
    "vm = VocabularyManager()\n",
    "vm.vocab_size\n",
    "\n",
    "TES = TiedEmbeddingSoftmax()\n",
    "TES.w.shape, TES.b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TiedEmbeddingSoftmax:\n\tWhile copying the parameter named \"w\", expected torch.Tensor or Tensor-like object from checkpoint but received <class 'NoneType'>\n\tsize mismatch for b: copying a param with shape torch.Size([129407]) from checkpoint, the shape in current model is torch.Size([10061]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mTES\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtied_embedding_softmax.w\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtied_embedding_softmax.b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m               \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/progen_env/lib/python3.10/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TiedEmbeddingSoftmax:\n\tWhile copying the parameter named \"w\", expected torch.Tensor or Tensor-like object from checkpoint but received <class 'NoneType'>\n\tsize mismatch for b: copying a param with shape torch.Size([129407]) from checkpoint, the shape in current model is torch.Size([10061])."
     ]
    }
   ],
   "source": [
    "TES.load_state_dict({\n",
    "                   'w': cp.pop('tied_embedding_softmax.w', None),\n",
    "                   'b': cp.pop('tied_embedding_softmax.b', None)\n",
    "               })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
