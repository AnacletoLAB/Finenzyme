{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import random\n",
    "import pickle\n",
    "scop_seqs = pd.read_csv('data_scop/scop_seqs_with_tags.gz')\n",
    "#drop duplicates on sequence\n",
    "scop_seqs = scop_seqs.drop_duplicates(subset='Sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create kw as a column of scop_seqs: that is a list of the elements in the columns named 'TP', 'CL' , 'CF' , 'SF' and 'FA'\n",
    "\n",
    "#scop_seqs['kw'] = scop_seqs[['TP', 'CL' , 'CF' , 'SF' , 'FA']].values.tolist()\n",
    "scop_seqs['kw'] = scop_seqs[['SF', 'FA', 'CL' , 'CF' , 'TP']].values.tolist()\n",
    "\n",
    "scop_seqs['Entry'] = range(0,len(scop_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(dataframe):\n",
    "    #convert the dataframes to dictionaries\n",
    "    dictionary = {}\n",
    "    for _, row in dataframe.iterrows():\n",
    "        sub_dict = {}\n",
    "        sub_dict[\"kw\"] = row[\"kw\"]\n",
    "        sub_dict[\"ex\"] = 4\n",
    "        sub_dict[\"seq\"] = row[\"Sequence\"]\n",
    "        sub_dict[\"len\"] = row[\"seq_length\"]\n",
    "        dictionary[row[\"Entry\"]] = sub_dict\n",
    "    # convert the dictionary items to a list, shuffle the list, and convert it back to a dictionary\n",
    "    items = list(dictionary.items())\n",
    "    random.shuffle(items)\n",
    "    return dict(items)\n",
    "\n",
    "def save_to_pickle(dictionary, path):\n",
    "    #save the dictionary to a pickle file\n",
    "    with open(path, \"wb\") as file:\n",
    "        pickle.dump(dictionary, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "path = \"data_scop/scop_seqs_with_tags.p\"\n",
    "dictionary = convert_to_dict(scop_seqs)\n",
    "save_to_pickle(dictionary, path)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scop_seqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      TP goes from 0 to 4,\n",
      "      CL goes from 4 to 9,\n",
      "      CF goes from 9 to 1540,\n",
      "      FA goes from 1540 to 7330,\n",
      "      SF goes from 7330 to 10035,\n",
      "      AA goes from 10035 to 10060\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "#Create a vocab.txt file, containing all tags from TP, CL, CF, FA, and SF   \n",
    "#The vocab.txt file will be used to create a vocabulary for the model\n",
    "#Its comprised of:\n",
    "#TAG [INCREMENTAL NUMBER]\\n\n",
    "#TAG [INCREMENTAL NUMBER]\\n\n",
    "\n",
    "#Also add the letters of the amino acids to the vocab.txt file at the end and the PAD token\n",
    "#The amino acids are all the letters of the alphabet\n",
    "\n",
    "\n",
    "\n",
    "vocab = pd.concat([scop_seqs[\"TP\"], scop_seqs[\"CL\"], scop_seqs[\"CF\"], scop_seqs[\"FA\"], scop_seqs[\"SF\"]] ).unique()\n",
    "#add the amino acids to the vocab\n",
    "vocab = list(vocab)\n",
    "vocab.extend(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'PAD'])\n",
    "\n",
    "\n",
    "\n",
    "TP_POS = 0\n",
    "CL_POS = scop_seqs[\"TP\"].unique().size\n",
    "CF_POS = scop_seqs[\"CL\"].unique().size + CL_POS\n",
    "FA_POS = scop_seqs[\"CF\"].unique().size + CF_POS\n",
    "SF_POS = scop_seqs[\"FA\"].unique().size + FA_POS\n",
    "AA_POS = scop_seqs[\"SF\"].unique().size + SF_POS\n",
    "PAD_POS = len(vocab) - 1\n",
    "\n",
    "print(f'''\n",
    "      TP goes from 0 to {CL_POS},\n",
    "      CL goes from {CL_POS} to {CF_POS},\n",
    "      CF goes from {CF_POS} to {FA_POS},\n",
    "      FA goes from {FA_POS} to {SF_POS},\n",
    "      SF goes from {SF_POS} to {AA_POS},\n",
    "      AA goes from {AA_POS} to {PAD_POS}\n",
    "      ''')\n",
    "\n",
    "vocab = pd.DataFrame(vocab)\n",
    "\n",
    "#include index before converting to csv\n",
    "vocab = vocab.reset_index()\n",
    "vocab.columns = [\"index\", \"tag\"]\n",
    "vocab[\"tag\"] = vocab[\"tag\"].astype(str) + \" \" + vocab[\"index\"].astype(str)\n",
    "vocab = vocab[\"tag\"]\n",
    "\n",
    "vocab.to_csv('mapping_files/vocab.txt', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
